{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e692b0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f406b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['problem', 'solution', 'messages'],\n",
      "    num_rows: 3622\n",
      "})\n",
      "{'problem': 'What is the coefficient of $x^2y^6$ in the expansion of $\\\\left(\\\\frac{3}{5}x-\\\\frac{y}{2}\\\\right)^8$?  Express your answer as a common fraction.', 'solution': \"To determine the coefficient of \\\\(x^2y^6\\\\) in the expansion of \\\\(\\\\left(\\\\frac{3}{5}x - \\\\frac{y}{2}\\\\right)^8\\\\), we can use the binomial theorem.\\n\\nThe binomial theorem states:\\n\\\\[\\n(a + b)^n = \\\\sum_{k=0}^{n} \\\\binom{n}{k} a^{n-k} b^k\\n\\\\]\\n\\nIn this case, \\\\(a = \\\\frac{3}{5}x\\\\), \\\\(b = -\\\\frac{y}{2}\\\\), and \\\\(n = 8\\\\).\\n\\nWe are interested in the term that contains \\\\(x^2y^6\\\\). In the general term of the binomial expansion:\\n\\\\[\\n\\\\binom{8}{k} \\\\left(\\\\frac{3}{5}x\\\\right)^{8-k} \\\\left(-\\\\frac{y}{2}\\\\right)^k\\n\\\\]\\n\\nTo get \\\\(x^2\\\\), we need \\\\(8 - k = 2\\\\), thus \\\\(k = 6\\\\).\\n\\nSubstituting \\\\(k = 6\\\\) into the expression:\\n\\\\[\\n\\\\binom{8}{6} \\\\left(\\\\frac{3}{5}x\\\\right)^{8-6} \\\\left(-\\\\frac{y}{2}\\\\right)^6 = \\\\binom{8}{6} \\\\left(\\\\frac{3}{5}x\\\\right)^2 \\\\left(-\\\\frac{y}{2}\\\\right)^6\\n\\\\]\\n\\nNow, we will compute each part of this expression.\\n\\n1. Calculate the binomial coefficient \\\\(\\\\binom{8}{6}\\\\).\\n2. Compute \\\\(\\\\left(\\\\frac{3}{5}\\\\right)^2\\\\).\\n3. Compute \\\\(\\\\left(-\\\\frac{y}{2}\\\\right)^6\\\\).\\n4. Combine everything together to get the coefficient of \\\\(x^2y^6\\\\).\\n\\nLet's compute these in Python.\\n```python\\nfrom math import comb\\n\\n# Given values\\nn = 8\\nk = 6\\n\\n# Calculate the binomial coefficient\\nbinom_coeff = comb(n, k)\\n\\n# Compute (3/5)^2\\na_term = (3/5)**2\\n\\n# Compute (-1/2)^6\\nb_term = (-1/2)**6\\n\\n# Combine terms to get the coefficient of x^2y^6\\ncoefficient = binom_coeff * a_term * b_term\\nprint(coefficient)\\n```\\n```output\\n0.1575\\n```\\nThe coefficient of \\\\(x^2y^6\\\\) in the expansion of \\\\(\\\\left(\\\\frac{3}{5}x - \\\\frac{y}{2}\\\\right)^8\\\\) is \\\\(0.1575\\\\). To express this as a common fraction, we recognize that:\\n\\n\\\\[ 0.1575 = \\\\frac{1575}{10000} = \\\\frac{63}{400} \\\\]\\n\\nThus, the coefficient can be expressed as:\\n\\n\\\\[\\n\\\\boxed{\\\\frac{63}{400}}\\n\\\\]\", 'messages': [{'content': 'What is the coefficient of $x^2y^6$ in the expansion of $\\\\left(\\\\frac{3}{5}x-\\\\frac{y}{2}\\\\right)^8$?  Express your answer as a common fraction.', 'role': 'user'}, {'content': \"To determine the coefficient of \\\\(x^2y^6\\\\) in the expansion of \\\\(\\\\left(\\\\frac{3}{5}x - \\\\frac{y}{2}\\\\right)^8\\\\), we can use the binomial theorem.\\n\\nThe binomial theorem states:\\n\\\\[\\n(a + b)^n = \\\\sum_{k=0}^{n} \\\\binom{n}{k} a^{n-k} b^k\\n\\\\]\\n\\nIn this case, \\\\(a = \\\\frac{3}{5}x\\\\), \\\\(b = -\\\\frac{y}{2}\\\\), and \\\\(n = 8\\\\).\\n\\nWe are interested in the term that contains \\\\(x^2y^6\\\\). In the general term of the binomial expansion:\\n\\\\[\\n\\\\binom{8}{k} \\\\left(\\\\frac{3}{5}x\\\\right)^{8-k} \\\\left(-\\\\frac{y}{2}\\\\right)^k\\n\\\\]\\n\\nTo get \\\\(x^2\\\\), we need \\\\(8 - k = 2\\\\), thus \\\\(k = 6\\\\).\\n\\nSubstituting \\\\(k = 6\\\\) into the expression:\\n\\\\[\\n\\\\binom{8}{6} \\\\left(\\\\frac{3}{5}x\\\\right)^{8-6} \\\\left(-\\\\frac{y}{2}\\\\right)^6 = \\\\binom{8}{6} \\\\left(\\\\frac{3}{5}x\\\\right)^2 \\\\left(-\\\\frac{y}{2}\\\\right)^6\\n\\\\]\\n\\nNow, we will compute each part of this expression.\\n\\n1. Calculate the binomial coefficient \\\\(\\\\binom{8}{6}\\\\).\\n2. Compute \\\\(\\\\left(\\\\frac{3}{5}\\\\right)^2\\\\).\\n3. Compute \\\\(\\\\left(-\\\\frac{y}{2}\\\\right)^6\\\\).\\n4. Combine everything together to get the coefficient of \\\\(x^2y^6\\\\).\\n\\nLet's compute these in Python.\\n```python\\nfrom math import comb\\n\\n# Given values\\nn = 8\\nk = 6\\n\\n# Calculate the binomial coefficient\\nbinom_coeff = comb(n, k)\\n\\n# Compute (3/5)^2\\na_term = (3/5)**2\\n\\n# Compute (-1/2)^6\\nb_term = (-1/2)**6\\n\\n# Combine terms to get the coefficient of x^2y^6\\ncoefficient = binom_coeff * a_term * b_term\\nprint(coefficient)\\n```\\n```output\\n0.1575\\n```\\nThe coefficient of \\\\(x^2y^6\\\\) in the expansion of \\\\(\\\\left(\\\\frac{3}{5}x - \\\\frac{y}{2}\\\\right)^8\\\\) is \\\\(0.1575\\\\). To express this as a common fraction, we recognize that:\\n\\n\\\\[ 0.1575 = \\\\frac{1575}{10000} = \\\\frac{63}{400} \\\\]\\n\\nThus, the coefficient can be expressed as:\\n\\n\\\\[\\n\\\\boxed{\\\\frac{63}{400}}\\n\\\\]\", 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_id = \"AI-MO/NuminaMath-TIR\"\n",
    "train_dataset, test_dataset = load_dataset(dataset_id, split=[\"train[:5%]\", \"test[:5%]\"])\n",
    "\n",
    "print(train_dataset)\n",
    "\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1915278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant \"\n",
    "    \"first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning \"\n",
    "    \"process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., \"\n",
    "    \"<think> reasoning process here </think><answer> answer here </answer>\"\n",
    ")\n",
    "\n",
    "\n",
    "def make_conversation(example):\n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": example[\"problem\"]},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(make_conversation)\n",
    "test_dataset = test_dataset.map(make_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b3cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>', 'role': 'system'}, {'content': 'What is the coefficient of $x^2y^6$ in the expansion of $\\\\left(\\\\frac{3}{5}x-\\\\frac{y}{2}\\\\right)^8$?  Express your answer as a common fraction.', 'role': 'user'}]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Column name ['problem', 'messages'] not in the dataset. Current columns in the dataset: ['solution', 'prompt']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(train_dataset[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_dataset = \u001b[43mtrain_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproblem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(train_dataset)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(test_dataset)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/hkomatsu/alternative/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/hkomatsu/alternative/.venv/lib/python3.12/site-packages/datasets/fingerprint.py:442\u001b[39m, in \u001b[36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/hkomatsu/alternative/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2161\u001b[39m, in \u001b[36mDataset.remove_columns\u001b[39m\u001b[34m(self, column_names, new_fingerprint)\u001b[39m\n\u001b[32m   2159\u001b[39m missing_columns = \u001b[38;5;28mset\u001b[39m(column_names) - \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m._data.column_names)\n\u001b[32m   2160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_columns:\n\u001b[32m-> \u001b[39m\u001b[32m2161\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2162\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(missing_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in the dataset. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrent columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset._data.column_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2164\u001b[39m     )\n\u001b[32m   2166\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m column_name \u001b[38;5;129;01min\u001b[39;00m column_names:\n\u001b[32m   2167\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m dataset._info.features[column_name]\n",
      "\u001b[31mValueError\u001b[39m: Column name ['problem', 'messages'] not in the dataset. Current columns in the dataset: ['solution', 'prompt']"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"prompt\"])\n",
    "train_dataset = train_dataset.remove_columns([\"messages\", \"problem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92097dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['solution', 'prompt'],\n",
      "    num_rows: 3622\n",
      "})\n",
      "{'messages': [{'content': \"In 1988, a person's age was equal to the sum of the \"\n",
      "                          'digits of their birth year. How old was this '\n",
      "                          'person?',\n",
      "               'role': 'user'},\n",
      "              {'content': \"To solve this problem, let's break it down \"\n",
      "                          'step-by-step:\\n'\n",
      "                          '\\n'\n",
      "                          \"1. Let the person's birth year be \\\\( Y \\\\).\\n\"\n",
      "                          \"2. In 1988, the person's age would be \\\\( 1988 - Y \"\n",
      "                          '\\\\).\\n'\n",
      "                          '3. The sum of the digits of \\\\( Y \\\\) should be '\n",
      "                          'equal to their age in 1988.\\n'\n",
      "                          '\\n'\n",
      "                          'Therefore, we need to find a year \\\\( Y \\\\) such '\n",
      "                          'that:\\n'\n",
      "                          '\\n'\n",
      "                          '\\\\[ 1988 - Y = \\\\text{sum of the digits of } Y \\\\]\\n'\n",
      "                          '\\n'\n",
      "                          'We can solve this by iterating through possible '\n",
      "                          'values for \\\\( Y \\\\) and checking if the condition '\n",
      "                          'holds.\\n'\n",
      "                          '\\n'\n",
      "                          \"Let's write a Python script to find the correct \"\n",
      "                          'birth year \\\\( Y \\\\).\\n'\n",
      "                          '```python\\n'\n",
      "                          'def digit_sum(year):\\n'\n",
      "                          '    \"\"\"Calculate the sum of the digits of a '\n",
      "                          'year.\"\"\"\\n'\n",
      "                          '    return sum(int(digit) for digit in str(year))\\n'\n",
      "                          '\\n'\n",
      "                          'def find_birth_year():\\n'\n",
      "                          'print((    for year in range(1900, 1989):))  # '\n",
      "                          'Reasonable range given the\\n'\n",
      "                          '```\\n'\n",
      "                          '```output\\n'\n",
      "                          'Cell In[210], line 6\\n'\n",
      "                          '    for year in range(1900, 1989):  # Reasonable '\n",
      "                          'range given the\\n'\n",
      "                          '                                                                '\n",
      "                          '^\\n'\n",
      "                          'SyntaxError: incomplete input\\n'\n",
      "                          '```\\n'\n",
      "                          'It looks like the code was cut off prematurely. Let '\n",
      "                          'me continue with the complete code included.\\n'\n",
      "                          '\\n'\n",
      "                          \"We'll define a function to compute the digit sum \"\n",
      "                          'and then iterate over possible birth years within a '\n",
      "                          'reasonable range to find the correct year that '\n",
      "                          'satisfies the condition.\\n'\n",
      "                          '```python\\n'\n",
      "                          'def digit_sum(year):\\n'\n",
      "                          '    \"\"\"Calculate the sum of the digits of a '\n",
      "                          'year.\"\"\"\\n'\n",
      "                          '    return sum(int(digit) for digit in str(year))\\n'\n",
      "                          '\\n'\n",
      "                          'def find_birth_year():\\n'\n",
      "                          '    for year in range(1900, 1989):  # Reasonable '\n",
      "                          'range given the context\\n'\n",
      "                          '        age_in_1988 = 1988 - year\\n'\n",
      "                          '        if age_in_1988 == digit_sum(year):\\n'\n",
      "                          '            return age_in_1988\\n'\n",
      "                          '        \\n'\n",
      "                          'age_1988 = find_birth_year()\\n'\n",
      "                          'print(age_1988)\\n'\n",
      "                          '```\\n'\n",
      "                          '```output\\n'\n",
      "                          '22\\n'\n",
      "                          '```\\n'\n",
      "                          \"The person's age in 1988 was \\\\( \\\\boxed{22} \\\\).\",\n",
      "               'role': 'assistant'}],\n",
      " 'problem': \"In 1988, a person's age was equal to the sum of the digits of \"\n",
      "            'their birth year. How old was this person?',\n",
      " 'prompt': [{'content': 'A conversation between User and Assistant. The user '\n",
      "                        'asks a question, and the Assistant solves it. The '\n",
      "                        'assistant first thinks about the reasoning process in '\n",
      "                        'the mind and then provides the user with the answer. '\n",
      "                        'The reasoning process and answer are enclosed within '\n",
      "                        '<think> </think> and <answer> </answer> tags, '\n",
      "                        'respectively, i.e., <think> reasoning process here '\n",
      "                        '</think><answer> answer here </answer>',\n",
      "             'role': 'system'},\n",
      "            {'content': \"In 1988, a person's age was equal to the sum of the \"\n",
      "                        'digits of their birth year. How old was this person?',\n",
      "             'role': 'user'}],\n",
      " 'solution': \"To solve this problem, let's break it down step-by-step:\\n\"\n",
      "             '\\n'\n",
      "             \"1. Let the person's birth year be \\\\( Y \\\\).\\n\"\n",
      "             \"2. In 1988, the person's age would be \\\\( 1988 - Y \\\\).\\n\"\n",
      "             '3. The sum of the digits of \\\\( Y \\\\) should be equal to their '\n",
      "             'age in 1988.\\n'\n",
      "             '\\n'\n",
      "             'Therefore, we need to find a year \\\\( Y \\\\) such that:\\n'\n",
      "             '\\n'\n",
      "             '\\\\[ 1988 - Y = \\\\text{sum of the digits of } Y \\\\]\\n'\n",
      "             '\\n'\n",
      "             'We can solve this by iterating through possible values for \\\\( Y '\n",
      "             '\\\\) and checking if the condition holds.\\n'\n",
      "             '\\n'\n",
      "             \"Let's write a Python script to find the correct birth year \\\\( Y \"\n",
      "             '\\\\).\\n'\n",
      "             '```python\\n'\n",
      "             'def digit_sum(year):\\n'\n",
      "             '    \"\"\"Calculate the sum of the digits of a year.\"\"\"\\n'\n",
      "             '    return sum(int(digit) for digit in str(year))\\n'\n",
      "             '\\n'\n",
      "             'def find_birth_year():\\n'\n",
      "             'print((    for year in range(1900, 1989):))  # Reasonable range '\n",
      "             'given the\\n'\n",
      "             '```\\n'\n",
      "             '```output\\n'\n",
      "             'Cell In[210], line 6\\n'\n",
      "             '    for year in range(1900, 1989):  # Reasonable range given '\n",
      "             'the\\n'\n",
      "             '                                                                '\n",
      "             '^\\n'\n",
      "             'SyntaxError: incomplete input\\n'\n",
      "             '```\\n'\n",
      "             'It looks like the code was cut off prematurely. Let me continue '\n",
      "             'with the complete code included.\\n'\n",
      "             '\\n'\n",
      "             \"We'll define a function to compute the digit sum and then \"\n",
      "             'iterate over possible birth years within a reasonable range to '\n",
      "             'find the correct year that satisfies the condition.\\n'\n",
      "             '```python\\n'\n",
      "             'def digit_sum(year):\\n'\n",
      "             '    \"\"\"Calculate the sum of the digits of a year.\"\"\"\\n'\n",
      "             '    return sum(int(digit) for digit in str(year))\\n'\n",
      "             '\\n'\n",
      "             'def find_birth_year():\\n'\n",
      "             '    for year in range(1900, 1989):  # Reasonable range given the '\n",
      "             'context\\n'\n",
      "             '        age_in_1988 = 1988 - year\\n'\n",
      "             '        if age_in_1988 == digit_sum(year):\\n'\n",
      "             '            return age_in_1988\\n'\n",
      "             '        \\n'\n",
      "             'age_1988 = find_birth_year()\\n'\n",
      "             'print(age_1988)\\n'\n",
      "             '```\\n'\n",
      "             '```output\\n'\n",
      "             '22\\n'\n",
      "             '```\\n'\n",
      "             \"The person's age in 1988 was \\\\( \\\\boxed{22} \\\\).\"}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(train_dataset)\n",
    "pprint(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4303b236",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a822e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22fc2ea2e8f45df85310543bc13d99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7c03e3b43d4e47901fb30c808db35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7e4580558f4acdb8129f912df4b314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_id = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ada69",
   "metadata": {},
   "source": [
    "## LoRAで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a8f162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 540,672 || all params: 494,573,440 || trainable%: 0.1093\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69da60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def format_reward(completions, **kwargs):\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"^<think>.*?</think>\\s*<answer>.*?</answer>$\"\n",
    "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, content) for content in completion_contents]\n",
    "    rewards_list = [1.0 if match else 0.0 for match in matches]\n",
    "    return [1.0 if match else 0.0 for match in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a32f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting math_verify\n",
      "  Downloading math_verify-0.8.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting latex2sympy2_extended==1.10.2 (from math_verify)\n",
      "  Downloading latex2sympy2_extended-1.10.2-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.12/site-packages (from latex2sympy2_extended==1.10.2->math_verify) (1.14.0)\n",
      "Collecting antlr4-python3-runtime<=4.13.2,>=4.9.3 (from latex2sympy2_extended==1.10.2->math_verify)\n",
      "  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy->latex2sympy2_extended==1.10.2->math_verify) (1.3.0)\n",
      "Downloading math_verify-0.8.0-py3-none-any.whl (29 kB)\n",
      "Downloading latex2sympy2_extended-1.10.2-py3-none-any.whl (207 kB)\n",
      "Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n",
      "Installing collected packages: antlr4-python3-runtime, latex2sympy2_extended, math_verify\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [math_verify]\u001b[0m [latex2sympy2_extended]\n",
      "\u001b[1A\u001b[2KSuccessfully installed antlr4-python3-runtime-4.13.2 latex2sympy2_extended-1.10.2 math_verify-0.8.0\n"
     ]
    }
   ],
   "source": [
    "from math_verify import LatexExtractionConfig, parse, verify\n",
    "\n",
    "\n",
    "def accuracy_reward(completions, **kwargs):\n",
    "    \"\"\"Reward function that checks if the completion is the same as the ground truth.\"\"\"\n",
    "    solutions = kwargs[\"solution\"]\n",
    "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
    "    rewards = []\n",
    "    for content, solution in zip(completion_contents, solutions):\n",
    "        gold_parsed = parse(solution, extraction_mode=\"first_match\", extraction_config=[LatexExtractionConfig()])\n",
    "        answer_parsed = parse(content, extraction_mode=\"first_match\", extraction_config=[LatexExtractionConfig()])\n",
    "        if len(gold_parsed) != 0:\n",
    "            try:\n",
    "                rewards.append(float(verify(answer_parsed, gold_parsed)))\n",
    "            except Exception:\n",
    "                rewards.append(0.0)\n",
    "        else:\n",
    "            rewards.append(1.0)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7fe4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig\n",
    "from pathlib import Path\n",
    "\n",
    "base_output_dir = \"outputs/\"\n",
    "\n",
    "# Configure training arguments using GRPOConfig\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=base_output_dir / \"Qwen2-0.5B-GRPO-test\",\n",
    "    learning_rate=1e-5,\n",
    "    remove_unused_columns=False,  # to access the solution column in accuracy_reward\n",
    "    gradient_accumulation_steps=16,\n",
    "    num_train_epochs=1,\n",
    "    bf16=True,\n",
    "    # Parameters that control de data preprocessing\n",
    "    max_completion_length=64,  # default: 256\n",
    "    num_generations=4,  # default: 8\n",
    "    max_prompt_length=128,  # default: 512\n",
    "    # Parameters related to reporting and saving\n",
    "    report_to=[\"wandb\"],\n",
    "    logging_steps=10,\n",
    "    push_to_hub=False,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "824d82ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-01 00:25:09 [__init__.py:244] Automatically detected platform cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb156762b174ec8b25d8d362b6237cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48d24c641ff4079a67b8b4a26cd979f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bac81d53a3a47ab94a9ab5df4f233c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e86a7b8f46450fae6a34a8a86cb709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtorotoki0329soft\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/shared/hkomatsu/alternative/wandb/run-20250801_002516-udnwbypb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/torotoki0329soft/huggingface/runs/udnwbypb' target=\"_blank\">Qwen2-0.5B-GRPO-test</a></strong> to <a href='https://wandb.ai/torotoki0329soft/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/torotoki0329soft/huggingface' target=\"_blank\">https://wandb.ai/torotoki0329soft/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/torotoki0329soft/huggingface/runs/udnwbypb' target=\"_blank\">https://wandb.ai/torotoki0329soft/huggingface/runs/udnwbypb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='113' max='113' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [113/113 12:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Timeout during comparison\n",
      "Timeout during comparison\n",
      "Timeout during comparison\n",
      "Timeout during comparison\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOTrainer\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model, reward_funcs=[format_reward, accuracy_reward], args=training_args, train_dataset=train_dataset\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model(training_args.output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b1d075",
   "metadata": {},
   "source": [
    "# Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f187a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bcef94b2be4b12b5d10e7d94a4d175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/719 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b420a7ccc8e14ac1ab46143f0eaaca7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/2.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9ea7f43e0a4da684e7eff73c8f7a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e849cf470b5848c48b892ff92469b550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29692e94ab7448d1b0ffc0a0b08d9edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c99eb1c3af4353aec5ef0fa0034112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6be49e7c9f04d0882bc0f7cc4b1d216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720b7084487e43daa0d07151fee2540c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/367 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>', 'role': 'system'}, {'content': \"In 1988, a person's age was equal to the sum of the digits of their birth year. How old was this person?\", 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"sergiopaniego/Qwen2-0.5B-GRPO\"\n",
    "trained_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "trained_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "print(test_dataset[\"prompt\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b3303e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_tag(text: str, tag: str) -> str | None:\n",
    "    #pattern = fr\"<{tag}>.*?</{tag}>\"\n",
    "    pattern = fr\".*?<{tag}>(.*?)</{tag}>.*?\"\n",
    "    matches = re.match(pattern, text)\n",
    "    return matches.group(1)\n",
    "\n",
    "print(extract_tag(\"This is <answer>35</answer>!\", \"answer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_reasoning(prompt):\n",
    "    # Build the prompt from the dataset\n",
    "    prompt = \" \".join(entry[\"content\"] for entry in prompt)\n",
    "\n",
    "    # Tokenize and move to the same device as the model\n",
    "    inputs = trained_tokenizer(prompt, return_tensors=\"pt\").to(trained_model.device)\n",
    "\n",
    "    # Generate text without gradients\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        output_ids = trained_model.generate(**inputs, max_length=500)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Decode and extract model response\n",
    "    generated_text = trained_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Get inference time\n",
    "    inference_duration = end_time - start_time\n",
    "\n",
    "    # Get number of generated tokens\n",
    "    num_input_tokens = inputs[\"input_ids\"].shape[1]\n",
    "    num_generated_tokens = output_ids.shape[1] - num_input_tokens\n",
    "\n",
    "    return generated_text, inference_duration, num_generated_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5eda08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer> In 1988, a person's age was equal to the sum of the digits of their birth year. How old was this person?<think> 20 years old </think><answer> 35 </answer>\n",
      "\n",
      "The reasoning process is: If the sum of the digits of the person's birth year is equal to the person's current age, then that person must be 20 years old. The answer is: 35.\n"
     ]
    }
   ],
   "source": [
    "prompt = test_dataset[\"prompt\"][0]\n",
    "generated_text, inference_duration, num_generated_tokens = generate_with_reasoning(prompt)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30a4ea41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 2.23 seconds\n",
      "Generated tokens: 65\n",
      "<think> 20 years old </think><answer> 35 </answer>\n",
      "\n",
      "The reasoning process is: If the sum of the digits of the person's birth year is equal to the person's current age, then that person must be 20 years old. The answer is: 35.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inference time: {inference_duration:.2f} seconds\")\n",
    "print(f\"Generated tokens: {num_generated_tokens}\")\n",
    "prompt_text = \" \".join(entry[\"content\"] for entry in prompt)\n",
    "response_text = generated_text[len(prompt_text) :].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fe40d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"In 1988, a person's age was equal to the sum of the digits of their birth year. How old was this person?\", 'role': 'user'}, {'content': 'To solve this problem, let\\'s break it down step-by-step:\\n\\n1. Let the person\\'s birth year be \\\\( Y \\\\).\\n2. In 1988, the person\\'s age would be \\\\( 1988 - Y \\\\).\\n3. The sum of the digits of \\\\( Y \\\\) should be equal to their age in 1988.\\n\\nTherefore, we need to find a year \\\\( Y \\\\) such that:\\n\\n\\\\[ 1988 - Y = \\\\text{sum of the digits of } Y \\\\]\\n\\nWe can solve this by iterating through possible values for \\\\( Y \\\\) and checking if the condition holds.\\n\\nLet\\'s write a Python script to find the correct birth year \\\\( Y \\\\).\\n```python\\ndef digit_sum(year):\\n    \"\"\"Calculate the sum of the digits of a year.\"\"\"\\n    return sum(int(digit) for digit in str(year))\\n\\ndef find_birth_year():\\nprint((    for year in range(1900, 1989):))  # Reasonable range given the\\n```\\n```output\\nCell In[210], line 6\\n    for year in range(1900, 1989):  # Reasonable range given the\\n                                                                ^\\nSyntaxError: incomplete input\\n```\\nIt looks like the code was cut off prematurely. Let me continue with the complete code included.\\n\\nWe\\'ll define a function to compute the digit sum and then iterate over possible birth years within a reasonable range to find the correct year that satisfies the condition.\\n```python\\ndef digit_sum(year):\\n    \"\"\"Calculate the sum of the digits of a year.\"\"\"\\n    return sum(int(digit) for digit in str(year))\\n\\ndef find_birth_year():\\n    for year in range(1900, 1989):  # Reasonable range given the context\\n        age_in_1988 = 1988 - year\\n        if age_in_1988 == digit_sum(year):\\n            return age_in_1988\\n        \\nage_1988 = find_birth_year()\\nprint(age_1988)\\n```\\n```output\\n22\\n```\\nThe person\\'s age in 1988 was \\\\( \\\\boxed{22} \\\\).', 'role': 'assistant'}]\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(test_dataset[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#print(test_dataset['solution'][0])\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mextract_answer_numinamath_tir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msolution\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# correct = 0\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# for example in test_dataset:\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#     prompt = example[\"prompt\"]\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#     generated_text, inference_duration, num_generated_tokens = generate_with_reasoning(prompt)\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#     predict = extract_tag(generated_text, \"answer\")\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#     example[\"\"]\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mextract_answer_numinamath_tir\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      3\u001b[39m matches = re.match(pattern, text)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(matches)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatches\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup\u001b[49m(\u001b[32m1\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "def extract_answer_numinamath_tir(text: str) -> str | None:\n",
    "    pattern = fr\".*?```output(.*?)```.*?\"\n",
    "    matches = re.match(pattern, text)\n",
    "    print(matches)\n",
    "    return matches.group(1)\n",
    "\n",
    "print(test_dataset['messages'][0])\n",
    "#print(test_dataset['solution'][0])\n",
    "extract_answer_numinamath_tir(test_dataset['solution'][0])\n",
    "\n",
    "# correct = 0\n",
    "# for example in test_dataset:\n",
    "#     prompt = example[\"prompt\"]\n",
    "#     generated_text, inference_duration, num_generated_tokens = generate_with_reasoning(prompt)\n",
    "#     predict = extract_tag(generated_text, \"answer\")\n",
    "#     example[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8215bb30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alternative",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
